{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0oJYJ9Ukoz1+9PJAmM2kI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LJW0719/CCTV_CNN/blob/main/2_Yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DFve8TPAMzoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time # to calculate frame\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "FP6hTrqAM6yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Video FIle"
      ],
      "metadata": {
        "id": "cCNNrwwQM9jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture('2021-08-06_10-00-00_fri_sunny_out_ja-ma_C0064.mp4')"
      ],
      "metadata": {
        "id": "pEGe147SM_Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Yolo"
      ],
      "metadata": {
        "id": "4Q-KphpSNAwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
      ],
      "metadata": {
        "id": "meqIfkg5NCqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect and Show Object"
      ],
      "metadata": {
        "id": "D-5RciPjNEsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make 'detectAndShow' Function"
      ],
      "metadata": {
        "id": "LMhwgj-5NHDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectAndShow(frame):\n",
        "    start_time = time.time()\n",
        "    img = cv2.resize(frame, None, fx=0.4, fy=0.4)\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "\n",
        "    # Set Window Size\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "\n",
        "    # Detect Object\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            # Boxing Detected Object \n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "               \n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Remove Noise\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    # Show Results\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(img, label, (x, y + 30), font, 1, color, 1)\n",
        "    end_time = time.time()\n",
        "    process_time = end_time - start_time\n",
        "    print(\"=== A frame took {:.3f} seconds\".format(process_time))\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "59g-4mvQNJtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Video"
      ],
      "metadata": {
        "id": "LVSnNl2iNRCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)"
      ],
      "metadata": {
        "id": "vBYIzEh0NS02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while video.isOpened():\n",
        "  ret, frame = video.read()\n",
        "\n",
        "  if ret:\n",
        "    detectAndShow(frame)\n",
        "    key = cv2.waitKey(10)\n",
        "\n",
        "    if key == ord('q'):\n",
        "      break\n",
        "  else:\n",
        "    break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kd8B332hNUK6",
        "outputId": "9f00f203-db80-43a1-8137-37fe133256e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect and Show Only People"
      ],
      "metadata": {
        "id": "H7UC8gSrNWS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make 'detectPeople' Function"
      ],
      "metadata": {
        "id": "eBFx7PqkZWI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectPeople(frame):\n",
        "    start_time = time.time()\n",
        "    img = cv2.resize(frame, None, fx=0.4, fy=0.4)\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if class_id == 0 and confidence > 0.5: # Change only this part, please input class id\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "               \n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            color = colors[i]\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "            cv2.putText(img, label, (x, y + 30), font, 1, color, 1)\n",
        "    end_time = time.time()\n",
        "    process_time = end_time - start_time\n",
        "    print(\"=== A frame took {:.3f} seconds\".format(process_time))\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "YBLbNlvLZZ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Video"
      ],
      "metadata": {
        "id": "Tef_Is_dbh3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "\n",
        "while video.isOpened():\n",
        "  ret, frame = video.read()\n",
        "\n",
        "  if ret:\n",
        "    detectPeople(frame)\n",
        "    key = cv2.waitKey(10)\n",
        "\n",
        "    if key == ord('q'):\n",
        "      break\n",
        "  else:\n",
        "    break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TX1SjhZMbs-5",
        "outputId": "d2036483-b4bd-4557-8f4c-241c7d34ee40"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}